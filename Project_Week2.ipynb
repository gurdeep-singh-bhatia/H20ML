{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling football stadium attendance using a GBM algorithm\n",
    "The aim of this script is to generate an artificial data set to perform a GBM algorithm and deal with overfitting.\n",
    "The script is slightly long, specially the data generation part, so do not hesitate to go fast through it. Thanks for you attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 day 3 hours 56 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Kolkata</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>4 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Gurdeep_Singh_ugwgkm</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.466 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         1 day 3 hours 56 mins\n",
       "H2O_cluster_timezone:       Asia/Kolkata\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.7\n",
       "H2O_cluster_version_age:    4 days\n",
       "H2O_cluster_name:           H2O_from_python_Gurdeep_Singh_ugwgkm\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.466 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.3 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a random data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "sampleSize = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating stadium sizes (rounded at the closest hundred)\n",
    "stadiumSize = []\n",
    "for i in range (sampleSize):\n",
    "    size = round(np.random.normal(loc = 50000, scale = 12000), -2)\n",
    "    if(size < 10000):\n",
    "        size = 10000\n",
    "    stadiumSize.append(size)\n",
    "#print(stadiumSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating players' total value (rounded at the closest thousand)\n",
    "playersValue = []\n",
    "for i in range (sampleSize):\n",
    "    # Hypothesis: players' value proportional to the stadium size + some randomness\n",
    "    playersValue.append(round(stadiumSize[i] * 20 + random.randrange(200000, 500000, 1), -3))\n",
    "#print(playersValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating players' average age\n",
    "playersAge = []\n",
    "for i in range (sampleSize):\n",
    "    # Hypothesis: age is completely random\n",
    "    playersAge.append(round(np.random.normal(27, 2), 2))\n",
    "#print(playersAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating teams' winning average\n",
    "victory = []\n",
    "for i in range (sampleSize):\n",
    "    # Hypothesis: winning 80% influenced by team's value + 20% of randomness\n",
    "    percentage = round(playersValue[i]/np.max(playersValue)*80 + np.random.normal(loc=0.5, scale=0.1)*20)\n",
    "    if(percentage < 0):\n",
    "        percentage = 0\n",
    "    elif(percentage > 100):\n",
    "        percentage = 100\n",
    "    victory.append(percentage)\n",
    "#print(victory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the output variable: average number of fans going to the stadium during the season\n",
    "attendance = []\n",
    "for i in range (sampleSize):\n",
    "    # Hypothesis 1: attendance = stadium size * 0.8 +- some randomness\n",
    "    v = round(np.random.normal(loc=stadiumSize[i]*0.6, scale = stadiumSize[i]*0.1), -2)\n",
    "    # Hypothesis 2: the higher the players' value, the higher the attendance\n",
    "    v = v + v*playersValue[i]/np.max(playersValue)*0.4\n",
    "    # Hypothesis 3: the higher the victory rate, the higher the attendance\n",
    "    v = v + v*victory[i]**0.5/100\n",
    "    # Correcting for extreme values\n",
    "    if(v < stadiumSize[i]*0.3):\n",
    "        v = stadiumSize[i]*0.2\n",
    "    elif(v > stadiumSize[i]*0.9):\n",
    "        v = stadiumSize[i]*0.9\n",
    "    attendance.append(round(v, -2))\n",
    "#print(attendance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StadiumSize  PlayersValue  PlayersAge  VictoryPercentage  StadiumAttendance\n",
      "0      60100.0     1429000.0       27.78               65.0            54000.0\n",
      "1      40600.0     1152000.0       27.45               52.0            36500.0\n",
      "2      39600.0     1038000.0       27.40               54.0            34600.0\n",
      "3      69800.0     1810000.0       26.21               81.0            53500.0\n",
      "4      59300.0     1526000.0       26.88               66.0            53400.0\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataframe\n",
    "teamsDF = pd.DataFrame(list(zip(stadiumSize, playersValue, playersAge, victory, attendance)))\n",
    "teamsDF.columns =['StadiumSize','PlayersValue','PlayersAge','VictoryPercentage', \"StadiumAttendance\"]\n",
    "print(teamsDF.head())  \n",
    "\n",
    "hf = h2o.H2OFrame(teamsDF, destination_frame = \"teams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "teams = h2o.get_frame(\"teams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling a GBM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test set\n",
    "train, test = teams.split_frame(\n",
    "    ratios = [0.8],\n",
    "    destination_frames = [\"teams_train\", \"teams_test\"],\n",
    "    seed = 123)\n",
    "train = h2o.get_frame(\"teams_train\")\n",
    "test = h2o.get_frame(\"teams_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StadiumSize', 'PlayersValue', 'PlayersAge', 'VictoryPercentage']\n"
     ]
    }
   ],
   "source": [
    "# Defining X and Y variables\n",
    "y = 'StadiumAttendance'\n",
    "ignoreFields = y\n",
    "x = [i for i in train.names if i not in ignoreFields]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Constructing a GBM algorithm (with default hyperparameters and no cross validation)\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "myGBM = H2OGradientBoostingEstimator(model_id = \"baseline_GBM\")\n",
    "myGBM.train(x, y, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GBM baseline model has a MAE of 3178 on the Train set and 4618 on the Test set\n"
     ]
    }
   ],
   "source": [
    "# Model performance\n",
    "print(\"The GBM baseline model has a MAE of %d on the Train set and %d on the Test set\"\n",
    "      % (myGBM.mae(train), myGBM.model_performance(test).mae()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model exhibits better results in the train set than in the test set. Our model overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Completely overfitted model\n",
    "myGBM_overfitted = H2OGradientBoostingEstimator(model_id = \"overfitted_GBM\", ntrees = 1000, max_depth = 10)\n",
    "myGBM_overfitted.train(x, y, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GBM overfitted model has a MAE of 285 on the Train set and 5324 on the Test set\n"
     ]
    }
   ],
   "source": [
    "print(\"The GBM overfitted model has a MAE of %d on the Train set and %d on the Test set\"\n",
    "      % (myGBM_overfitted.mae(train), myGBM_overfitted.model_performance(test).mae()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the train error has significantly falled while the test error has increased. We can conclude that this specification indeed increases the previous overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Constructing a final GBM: using cross validation to reduce overfitting\n",
    "myGBM_cv = H2OGradientBoostingEstimator(model_id = \"crossval_GBM\", nfolds = 20)\n",
    "myGBM_cv.train(x, y, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GBM with cross validation model has a MAE of 3178 on the Train set and 4618 on the Test set\n"
     ]
    }
   ],
   "source": [
    "print(\"The GBM with cross validation model has a MAE of %d on the Train set and %d on the Test set\"\n",
    "      % (myGBM_cv.mae(train), myGBM_cv.model_performance(test).mae()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results exhibited by our CV model seem to be exactly the same as our baseline GBM. While using Cross Val, we train on different samples, so that the results are not supposed to be equal to a default GBM. I suppose I did a mistake somewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
